{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment & Topics Analysis from Telegram HTML Export\n",
    "\n",
    "This notebook analyses a Telegram chat export (HTML) using three Hugging Face models:\n",
    "- Emotion: https://huggingface.co/Aniemore/rubert-tiny2-russian-emotion-detection\n",
    "- Toxicity: https://huggingface.co/s-nlp/russian_toxicity_classifier\n",
    "- Sensitive topics: https://huggingface.co/apanc/russian-sensitive-topics\n",
    "\n",
    "It also segments the chat into conversations by time-gap (e.g., 30 minutes) and aggregates model outputs per conversation."
   ],
   "id": "ea82811ec34c2084"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T14:33:07.484013Z",
     "start_time": "2025-09-23T14:32:12.792242Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install -q transformers accelerate torch --upgrade",
   "id": "8335c5937a3b8ec5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T14:41:37.424074Z",
     "start_time": "2025-09-23T14:41:34.821641Z"
    }
   },
   "source": [
    "# Optional: install dependencies in this environment\n",
    "# If transformers/torch aren't installed, uncomment and run:\n",
    "# %pip install -q transformers accelerate torch --upgrade\n",
    "\n",
    "import math\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import pipeline\n",
    "\n",
    "from message_analyser.retriever.telegram_html import get_mymessages_from_html\n",
    "\n",
    "# Configure paths and names\n",
    "export_path = \"/Users/danuhaha/Downloads/Telegram Lite/ChatExport_2025-09-20\"  # e.g., '/Users/me/Downloads/ChatExport_2025-09-21'\n",
    "your_name = \"Даня Горин\"\n",
    "target_name = \"Ваня\"\n",
    "\n",
    "# Conversation segmentation threshold (in minutes)\n",
    "GAP_MINUTES = 60\n",
    "\n",
    "assert Path(export_path).exists(), f'Export path not found: {export_path}'\n"
   ],
   "id": "2db8e53b0c8fd567",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danuhaha/PycharmProjects/message-analyser/venv_modern/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T14:41:57.176247Z",
     "start_time": "2025-09-23T14:41:39.355103Z"
    }
   },
   "source": [
    "# Load messages\n",
    "msgs = get_mymessages_from_html(export_path, your_name, target_name)\n",
    "len(msgs), msgs[0].date, msgs[-1].date\n"
   ],
   "id": "6a151b5a1840412",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 17:41:57,173 - 38688 messages parsed from Telegram HTML export at /Users/danuhaha/Downloads/Telegram Lite/ChatExport_2025-09-20\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38688,\n",
       " datetime.datetime(2024, 9, 16, 20, 56, 54),\n",
       " datetime.datetime(2025, 9, 20, 22, 41, 8))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T14:42:24.066462Z",
     "start_time": "2025-09-23T14:42:23.869436Z"
    }
   },
   "source": [
    "# Segment into conversations by time gap\n",
    "def split_into_conversations(messages, gap_minutes=30):\n",
    "    if not messages:\n",
    "        return []\n",
    "    convos = []\n",
    "    current = [messages[0]]\n",
    "    gap = timedelta(minutes=gap_minutes)\n",
    "    for m in messages[1:]:\n",
    "        if (m.date - current[-1].date) > gap:\n",
    "            convos.append(current)\n",
    "            current = [m]\n",
    "        else:\n",
    "            current.append(m)\n",
    "    convos.append(current)\n",
    "    return convos\n",
    "\n",
    "conversations = split_into_conversations(msgs, GAP_MINUTES)\n",
    "len(conversations), conversations[0][0].date, conversations[0][-1].date\n"
   ],
   "id": "bfd639feae4df94e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1939,\n",
       " datetime.datetime(2024, 9, 16, 20, 56, 54),\n",
       " datetime.datetime(2024, 9, 16, 22, 39, 25))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T14:55:14.909512Z",
     "start_time": "2025-09-23T14:42:26.039985Z"
    }
   },
   "source": [
    "# Prepare and load models\n",
    "device = -1  # set -1 for CPU if needed\n",
    "\n",
    "emo_pipe = pipeline(\n",
    "    'text-classification',\n",
    "    model='Aniemore/rubert-tiny2-russian-emotion-detection',\n",
    "    device=device,\n",
    "    top_k=None,\n",
    ")\n",
    "tox_pipe = pipeline(\n",
    "    'text-classification',\n",
    "    model='s-nlp/russian_toxicity_classifier',\n",
    "    device=device,\n",
    "    top_k=None,\n",
    ")\n",
    "sens_pipe = pipeline(\n",
    "    'text-classification',\n",
    "    model='apanc/russian-sensitive-topics',\n",
    "    device=device,\n",
    "    top_k=None,\n",
    ")\n",
    "'models ready'\n"
   ],
   "id": "ea4f6481a715079c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models ready'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T15:08:06.801722Z",
     "start_time": "2025-09-23T15:08:06.791159Z"
    }
   },
   "source": [
    "# Helpers to run pipelines safely on many short texts\n",
    "def batched(iterable, n=64):\n",
    "    batch = []\n",
    "    for x in iterable:\n",
    "        batch.append(x)\n",
    "        if len(batch) >= n:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    if batch:\n",
    "        yield batch\n",
    "\n",
    "def run_pipe_avg_scores(pipe, texts: List[str]) -> Dict[str, float]:\n",
    "    # Returns mean score per label across texts\n",
    "    agg: Dict[str, float] = {}\n",
    "    count = 0\n",
    "    for batch in batched(texts, 32):\n",
    "        outs = pipe(batch, truncation=True, max_length=256)\n",
    "        # outs can be list[list[dict(label, score)]] or list[dict]\n",
    "        for res in outs:\n",
    "            count += 1\n",
    "            if isinstance(res, list):\n",
    "                for d in res:\n",
    "                    agg[d['label']] = agg.get(d['label'], 0.0) + float(d['score'])\n",
    "            elif isinstance(res, dict):\n",
    "                agg[res['label']] = agg.get(res['label'], 0.0) + float(res['score'])\n",
    "    if count == 0:\n",
    "        return {}\n",
    "    return {k: v / count for k, v in agg.items()}\n",
    "\n",
    "def run_pipe_frac_above(pipe, texts: List[str], positive_labels=None, threshold=0.5) -> float:\n",
    "    # Returns fraction of texts considered positive/toxic etc.\n",
    "    if positive_labels is not None:\n",
    "        positive_labels = set(positive_labels)\n",
    "    pos = 0\n",
    "    total = 0\n",
    "    for batch in batched(texts, 64):\n",
    "        outs = pipe(batch, truncation=True, max_length=256)\n",
    "        for res in outs:\n",
    "            total += 1\n",
    "            if isinstance(res, list):\n",
    "                # take max label\n",
    "                best = max(res, key=lambda d: d['score'])\n",
    "                lab, score = best['label'], float(best['score'])\n",
    "            else:\n",
    "                lab, score = res['label'], float(res['score'])\n",
    "            if (positive_labels is None and score >= threshold) or (positive_labels and lab in positive_labels and score >= threshold):\n",
    "                pos += 1\n",
    "    return (pos / total) if total else 0.0\n",
    "\n",
    "def normalize_texts(msgs, min_len=5):\n",
    "    return [m.text.strip() for m in msgs if m.text and len(m.text.strip()) >= min_len]\n",
    "\n",
    "def sample_texts(texts: List[str], max_per_convo=200):\n",
    "    if len(texts) <= max_per_convo:\n",
    "        return texts\n",
    "    # uniform downsample across the span\n",
    "    step = len(texts) / max_per_convo\n",
    "    return [texts[math.floor(i*step)] for i in range(max_per_convo)]\n",
    "\n",
    "'helpers ready'\n"
   ],
   "id": "4d486bf229c8808b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'helpers ready'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T15:27:15.857153Z",
     "start_time": "2025-09-23T15:08:19.230714Z"
    }
   },
   "source": [
    "# Analyse per conversation\n",
    "rows = []\n",
    "for idx, conv in enumerate(tqdm(conversations, desc='Conversations')):\n",
    "    texts_all = normalize_texts(conv)\n",
    "    if not texts_all:\n",
    "        continue\n",
    "    texts = sample_texts(texts_all, max_per_convo=200)\n",
    "\n",
    "    emo_scores = run_pipe_avg_scores(emo_pipe, texts)\n",
    "    tox_frac = run_pipe_frac_above(tox_pipe, texts, positive_labels={'toxic', 'toxicity', 'TOXIC'})\n",
    "    sens_scores = run_pipe_avg_scores(sens_pipe, texts)\n",
    "\n",
    "    start, end = conv[0].date, conv[-1].date\n",
    "    rows.append({\n",
    "        'conversation_id': idx,\n",
    "        'start': start,\n",
    "        'end': end,\n",
    "        'duration_min': (end - start).total_seconds() / 60.0,\n",
    "        'num_messages': len(conv),\n",
    "        'num_texts_used': len(texts),\n",
    "        'toxicity_rate': tox_frac,\n",
    "        **{f'emo_{k}': v for k, v in emo_scores.items()},\n",
    "        **{f'topic_{k}': v for k, v in sens_scores.items()},\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(['start']).reset_index(drop=True)\n",
    "df.head()\n"
   ],
   "id": "82b1d1832107c07",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversations: 100%|██████████| 1939/1939 [18:56<00:00,  1.71it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   conversation_id               start                 end  duration_min  \\\n",
       "0                0 2024-09-16 20:56:54 2024-09-16 22:39:25    102.516667   \n",
       "1                1 2024-09-17 08:39:22 2024-09-17 14:07:55    328.550000   \n",
       "2                2 2024-09-17 15:09:48 2024-09-17 16:19:18     69.500000   \n",
       "3                3 2024-09-17 17:27:19 2024-09-17 23:20:13    352.900000   \n",
       "4                4 2024-09-18 06:40:56 2024-09-18 09:59:28    198.533333   \n",
       "\n",
       "   num_messages  num_texts_used  toxicity_rate  emo_happiness  emo_sadness  \\\n",
       "0           119             103       0.116505       0.249543     0.097161   \n",
       "1           187             173       0.069364       0.261177     0.093819   \n",
       "2            72              55       0.145455       0.209552     0.073617   \n",
       "3           336             200       0.095000       0.254439     0.102971   \n",
       "4           146             124       0.145161       0.312804     0.094990   \n",
       "\n",
       "   emo_neutral  ...  topic_LABEL_340  topic_LABEL_251  topic_LABEL_235  \\\n",
       "0     0.303723  ...         0.000010         0.000009         0.000012   \n",
       "1     0.356412  ...         0.000015         0.000021         0.000026   \n",
       "2     0.356981  ...         0.000047         0.000074         0.000060   \n",
       "3     0.368406  ...         0.000008         0.000012         0.000014   \n",
       "4     0.267474  ...         0.000031         0.000047         0.000045   \n",
       "\n",
       "   topic_LABEL_176  topic_LABEL_205  topic_LABEL_347  topic_LABEL_282  \\\n",
       "0         0.000008         0.000007         0.000007         0.000009   \n",
       "1         0.000020         0.000013         0.000010         0.000012   \n",
       "2         0.000066         0.000040         0.000043         0.000063   \n",
       "3         0.000010         0.000008         0.000008         0.000011   \n",
       "4         0.000035         0.000043         0.000023         0.000025   \n",
       "\n",
       "   topic_LABEL_171  topic_LABEL_195  topic_LABEL_229  \n",
       "0         0.000010         0.000007         0.000006  \n",
       "1         0.000022         0.000018         0.000012  \n",
       "2         0.000053         0.000049         0.000043  \n",
       "3         0.000013         0.000009         0.000007  \n",
       "4         0.000062         0.000043         0.000031  \n",
       "\n",
       "[5 rows x 407 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration_min</th>\n",
       "      <th>num_messages</th>\n",
       "      <th>num_texts_used</th>\n",
       "      <th>toxicity_rate</th>\n",
       "      <th>emo_happiness</th>\n",
       "      <th>emo_sadness</th>\n",
       "      <th>emo_neutral</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_LABEL_340</th>\n",
       "      <th>topic_LABEL_251</th>\n",
       "      <th>topic_LABEL_235</th>\n",
       "      <th>topic_LABEL_176</th>\n",
       "      <th>topic_LABEL_205</th>\n",
       "      <th>topic_LABEL_347</th>\n",
       "      <th>topic_LABEL_282</th>\n",
       "      <th>topic_LABEL_171</th>\n",
       "      <th>topic_LABEL_195</th>\n",
       "      <th>topic_LABEL_229</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-16 20:56:54</td>\n",
       "      <td>2024-09-16 22:39:25</td>\n",
       "      <td>102.516667</td>\n",
       "      <td>119</td>\n",
       "      <td>103</td>\n",
       "      <td>0.116505</td>\n",
       "      <td>0.249543</td>\n",
       "      <td>0.097161</td>\n",
       "      <td>0.303723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-17 08:39:22</td>\n",
       "      <td>2024-09-17 14:07:55</td>\n",
       "      <td>328.550000</td>\n",
       "      <td>187</td>\n",
       "      <td>173</td>\n",
       "      <td>0.069364</td>\n",
       "      <td>0.261177</td>\n",
       "      <td>0.093819</td>\n",
       "      <td>0.356412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-09-17 15:09:48</td>\n",
       "      <td>2024-09-17 16:19:18</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>72</td>\n",
       "      <td>55</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.209552</td>\n",
       "      <td>0.073617</td>\n",
       "      <td>0.356981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-09-17 17:27:19</td>\n",
       "      <td>2024-09-17 23:20:13</td>\n",
       "      <td>352.900000</td>\n",
       "      <td>336</td>\n",
       "      <td>200</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.254439</td>\n",
       "      <td>0.102971</td>\n",
       "      <td>0.368406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-09-18 06:40:56</td>\n",
       "      <td>2024-09-18 09:59:28</td>\n",
       "      <td>198.533333</td>\n",
       "      <td>146</td>\n",
       "      <td>124</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.312804</td>\n",
       "      <td>0.094990</td>\n",
       "      <td>0.267474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 407 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T15:28:46.927803Z",
     "start_time": "2025-09-23T15:28:46.465335Z"
    }
   },
   "source": [
    "# Derive convenient summaries\n",
    "emo_cols = [c for c in df.columns if c.startswith('emo_')]\n",
    "topic_cols = [c for c in df.columns if c.startswith('topic_')]\n",
    "\n",
    "def topk(series: pd.Series, k=3):\n",
    "    return ', '.join([f\"{name}:{series[name]:.2f}\" for name in series.nlargest(k).index])\n",
    "\n",
    "df['top_emotions'] = df[emo_cols].apply(topk, axis=1) if emo_cols else ''\n",
    "df['top_topics'] = df[topic_cols].apply(topk, axis=1) if topic_cols else ''\n",
    "\n",
    "df[['conversation_id','start','end','num_messages','toxicity_rate','top_emotions','top_topics']].head(10)\n"
   ],
   "id": "d4ad47ae678b8ed7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   conversation_id               start                 end  num_messages  \\\n",
       "0                0 2024-09-16 20:56:54 2024-09-16 22:39:25           119   \n",
       "1                1 2024-09-17 08:39:22 2024-09-17 14:07:55           187   \n",
       "2                2 2024-09-17 15:09:48 2024-09-17 16:19:18            72   \n",
       "3                3 2024-09-17 17:27:19 2024-09-17 23:20:13           336   \n",
       "4                4 2024-09-18 06:40:56 2024-09-18 09:59:28           146   \n",
       "5                5 2024-09-18 11:21:15 2024-09-18 11:45:12            44   \n",
       "6                6 2024-09-18 13:14:48 2024-09-18 20:26:00           237   \n",
       "7                7 2024-09-19 00:49:08 2024-09-19 00:52:13             4   \n",
       "8                8 2024-09-19 07:04:11 2024-09-19 08:50:21            64   \n",
       "9                9 2024-09-19 10:46:25 2024-09-19 10:59:59            26   \n",
       "\n",
       "   toxicity_rate                                       top_emotions  \\\n",
       "0       0.116505  emo_neutral:0.30, emo_happiness:0.25, emo_enth...   \n",
       "1       0.069364  emo_neutral:0.36, emo_happiness:0.26, emo_enth...   \n",
       "2       0.145455  emo_neutral:0.36, emo_happiness:0.21, emo_ange...   \n",
       "3       0.095000  emo_neutral:0.37, emo_happiness:0.25, emo_enth...   \n",
       "4       0.145161  emo_happiness:0.31, emo_neutral:0.27, emo_enth...   \n",
       "5       0.111111  emo_neutral:0.36, emo_happiness:0.19, emo_ange...   \n",
       "6       0.125000  emo_neutral:0.33, emo_happiness:0.22, emo_sadn...   \n",
       "7       0.333333  emo_happiness:0.36, emo_fear:0.31, emo_sadness...   \n",
       "8       0.066667  emo_happiness:0.31, emo_neutral:0.27, emo_enth...   \n",
       "9       0.125000  emo_neutral:0.27, emo_sadness:0.23, emo_happin...   \n",
       "\n",
       "                                          top_topics  \n",
       "0  topic_LABEL_0:0.92, topic_LABEL_5:0.02, topic_...  \n",
       "1  topic_LABEL_0:0.86, topic_LABEL_12:0.03, topic...  \n",
       "2  topic_LABEL_0:0.71, topic_LABEL_3:0.08, topic_...  \n",
       "3  topic_LABEL_0:0.84, topic_LABEL_5:0.05, topic_...  \n",
       "4  topic_LABEL_0:0.79, topic_LABEL_13:0.04, topic...  \n",
       "5  topic_LABEL_0:0.88, topic_LABEL_3:0.03, topic_...  \n",
       "6  topic_LABEL_0:0.86, topic_LABEL_1:0.02, topic_...  \n",
       "7  topic_LABEL_0:1.00, topic_LABEL_2:0.00, topic_...  \n",
       "8  topic_LABEL_0:0.89, topic_LABEL_5:0.05, topic_...  \n",
       "9  topic_LABEL_0:0.81, topic_LABEL_1:0.08, topic_...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>num_messages</th>\n",
       "      <th>toxicity_rate</th>\n",
       "      <th>top_emotions</th>\n",
       "      <th>top_topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024-09-16 20:56:54</td>\n",
       "      <td>2024-09-16 22:39:25</td>\n",
       "      <td>119</td>\n",
       "      <td>0.116505</td>\n",
       "      <td>emo_neutral:0.30, emo_happiness:0.25, emo_enth...</td>\n",
       "      <td>topic_LABEL_0:0.92, topic_LABEL_5:0.02, topic_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-09-17 08:39:22</td>\n",
       "      <td>2024-09-17 14:07:55</td>\n",
       "      <td>187</td>\n",
       "      <td>0.069364</td>\n",
       "      <td>emo_neutral:0.36, emo_happiness:0.26, emo_enth...</td>\n",
       "      <td>topic_LABEL_0:0.86, topic_LABEL_12:0.03, topic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-09-17 15:09:48</td>\n",
       "      <td>2024-09-17 16:19:18</td>\n",
       "      <td>72</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>emo_neutral:0.36, emo_happiness:0.21, emo_ange...</td>\n",
       "      <td>topic_LABEL_0:0.71, topic_LABEL_3:0.08, topic_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-09-17 17:27:19</td>\n",
       "      <td>2024-09-17 23:20:13</td>\n",
       "      <td>336</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>emo_neutral:0.37, emo_happiness:0.25, emo_enth...</td>\n",
       "      <td>topic_LABEL_0:0.84, topic_LABEL_5:0.05, topic_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-09-18 06:40:56</td>\n",
       "      <td>2024-09-18 09:59:28</td>\n",
       "      <td>146</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>emo_happiness:0.31, emo_neutral:0.27, emo_enth...</td>\n",
       "      <td>topic_LABEL_0:0.79, topic_LABEL_13:0.04, topic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-09-18 11:21:15</td>\n",
       "      <td>2024-09-18 11:45:12</td>\n",
       "      <td>44</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>emo_neutral:0.36, emo_happiness:0.19, emo_ange...</td>\n",
       "      <td>topic_LABEL_0:0.88, topic_LABEL_3:0.03, topic_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2024-09-18 13:14:48</td>\n",
       "      <td>2024-09-18 20:26:00</td>\n",
       "      <td>237</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>emo_neutral:0.33, emo_happiness:0.22, emo_sadn...</td>\n",
       "      <td>topic_LABEL_0:0.86, topic_LABEL_1:0.02, topic_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2024-09-19 00:49:08</td>\n",
       "      <td>2024-09-19 00:52:13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>emo_happiness:0.36, emo_fear:0.31, emo_sadness...</td>\n",
       "      <td>topic_LABEL_0:1.00, topic_LABEL_2:0.00, topic_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2024-09-19 07:04:11</td>\n",
       "      <td>2024-09-19 08:50:21</td>\n",
       "      <td>64</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>emo_happiness:0.31, emo_neutral:0.27, emo_enth...</td>\n",
       "      <td>topic_LABEL_0:0.89, topic_LABEL_5:0.05, topic_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2024-09-19 10:46:25</td>\n",
       "      <td>2024-09-19 10:59:59</td>\n",
       "      <td>26</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>emo_neutral:0.27, emo_sadness:0.23, emo_happin...</td>\n",
       "      <td>topic_LABEL_0:0.81, topic_LABEL_1:0.08, topic_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T15:29:09.395341Z",
     "start_time": "2025-09-23T15:29:08.964515Z"
    }
   },
   "source": [
    "# Save results next to the export or in repo results/\n",
    "out_dir = Path(export_path)/'analysis_outputs'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_csv = out_dir/'sentiment_topics_by_conversation.csv'\n",
    "df.to_csv(out_csv, index=False)\n",
    "out_csv\n"
   ],
   "id": "71668dcec0301ec2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/danuhaha/Downloads/Telegram Lite/ChatExport_2025-09-20/analysis_outputs/sentiment_topics_by_conversation.csv')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole chat rollups\n",
    "You can also aggregate across all messages to get overall emotion/topic averages and toxicity rate."
   ],
   "id": "947b3f94d2a8b09f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T15:30:18.383651Z",
     "start_time": "2025-09-23T15:29:13.599783Z"
    }
   },
   "source": [
    "texts_all = [m.text.strip() for m in msgs if m.text and len(m.text.strip()) >= 5]\n",
    "texts_all = sample_texts(texts_all, max_per_convo=2000)  # cap for speed\n",
    "emo_all = run_pipe_avg_scores(emo_pipe, texts_all)\n",
    "tox_all = run_pipe_frac_above(tox_pipe, texts_all, positive_labels={'toxic','toxicity','TOXIC'})\n",
    "sens_all = run_pipe_avg_scores(sens_pipe, texts_all)\n",
    "\n",
    "pd.Series(emo_all).sort_values(ascending=False), tox_all, pd.Series(sens_all).sort_values(ascending=False)[:10]\n"
   ],
   "id": "fa78e57613f9f39c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(neutral       0.363574\n",
       " happiness     0.234025\n",
       " enthusiasm    0.142145\n",
       " anger         0.106395\n",
       " sadness       0.090913\n",
       " fear          0.035365\n",
       " disgust       0.008148\n",
       " dtype: float64,\n",
       " 0.065,\n",
       " LABEL_0     0.845862\n",
       " LABEL_5     0.021906\n",
       " LABEL_12    0.019068\n",
       " LABEL_18    0.015486\n",
       " LABEL_11    0.010701\n",
       " LABEL_4     0.010244\n",
       " LABEL_13    0.009779\n",
       " LABEL_1     0.008752\n",
       " LABEL_2     0.008642\n",
       " LABEL_3     0.008360\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
